{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporting an AstroID REDCap build and importing into MSSQL\n",
    "\n",
    "Created by: Benjamin Green - 03.10.2024;\n",
    "Last Edit 06.14.2024;\n",
    "Python 3.10.14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get started, pip install the corresponding packages and import them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import requests\n",
    "import numpy\n",
    "import pandas\n",
    "import geopandas\n",
    "from sqlalchemy import create_engine, MetaData\n",
    "import sqlalchemy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, set up the input variables below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "token = '' # A REDCap API token\n",
    "username = '' # A username for an SQL database\n",
    "password = '' # A password for an SQL database\n",
    "ip = '' # An ip address for an SQL database\n",
    "port = '' # A port for an SQL database\n",
    "key_1 = 'patient_tier' # The first tier in the cascading structure as described in the AstroID format\n",
    "pt_id = 'astropt' # The patient identifier for the cascading structure as described in the AstroID format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, run the following cell. This will create the appropriate functions and classes to read the data from REDCap, organize them, and load them into a SQL database. It will not run any of the code, just set things up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_request_input(token, content, beginTime = '2020-01-16 15:10', endTime = ''):\n",
    "    \"\"\"\n",
    "    create input JSON for requests.post\n",
    "\n",
    "    Args:\n",
    "        token: redcap token\n",
    "        content: redcap table/form to use\n",
    "    \"\"\"\n",
    "    if content == 'log':\n",
    "        return {\n",
    "            'token': token,\n",
    "            'content': content,\n",
    "            'logtype': '',\n",
    "            'user': '',\n",
    "            'record': '',\n",
    "            'beginTime': beginTime,\n",
    "            'endTime': endTime,\n",
    "            'format': 'csv',\n",
    "            'returnFormat': 'json'\n",
    "        }\n",
    "    if content == 'record':\n",
    "        return {\n",
    "            'token': token,\n",
    "            'content': content,\n",
    "            'action': 'export',\n",
    "            'format': 'csv',\n",
    "            'type': 'flat',\n",
    "            'csvDelimiter': '',\n",
    "            'rawOrLabel': 'raw',\n",
    "            'rawOrLabelHeaders': 'raw',\n",
    "            'exportCheckboxLabel': 'false',\n",
    "            'exportSurveyFields': 'false',\n",
    "            'exportDataAccessGroups': 'false',\n",
    "            'returnFormat': 'json'\n",
    "        }\n",
    "    return {\n",
    "        'token': token,\n",
    "        'content': content,\n",
    "        'format': 'csv',\n",
    "        'returnFormat': 'json'\n",
    "    }\n",
    "\n",
    "def request_redcap_data(\n",
    "        token,\n",
    "        content,\n",
    "        redcap_link = 'https://mrprcbcw.hosts.jhmi.edu/redcap/api/',\n",
    "    ):\n",
    "    \"\"\"\n",
    "    send the data request to redcap\n",
    "    \n",
    "    Args:\n",
    "        token: redcap token\n",
    "        content: redcap table/form to use\n",
    "        redcap_link: link to redcap\n",
    "    \"\"\"\n",
    "    return requests.post(\n",
    "        redcap_link,\n",
    "        data=create_request_input(token, content),\n",
    "    )\n",
    "\n",
    "def get_redcap_df(token, content):\n",
    "    \"\"\"\n",
    "    convert the text output from the redcap \n",
    "    request to pandas df\n",
    "\n",
    "    Args:\n",
    "        token: redcap token\n",
    "        content: redcap table/form to use\n",
    "    \"\"\"\n",
    "    return pandas.read_csv(\n",
    "        io.StringIO(request_redcap_data(token, content).text), dtype= str,\n",
    "    )\n",
    "\n",
    "class DBUtils:\n",
    "    \"\"\"\n",
    "    create a direct connection to the database. specifically\n",
    "    helpful when we need to write a table to the database.\n",
    "    More advanced permissions are needed for this.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.dbengine = None\n",
    "        self.dbmeta = None\n",
    "        self.creds = dict.fromkeys({\"username\", \"password\", \"IP\", \"port\"})\n",
    "\n",
    "    def open_connection(self, database=\"AstroPathXfer\"):\n",
    "        \"\"\"\n",
    "        create a direct database connection and return\n",
    "        the engine as well as the meta data object\n",
    "        for that database.\n",
    "\n",
    "        Args:\n",
    "            creds: a dictionary with username, password,\n",
    "                IP and port for the connection.\n",
    "            database: database to connect to\n",
    "        \"\"\"\n",
    "        #\n",
    "        self.dbengine = create_engine(\n",
    "            f\"\"\"mssql+pymssql://{self.creds['username']}:{\n",
    "                self.creds['password']}@{self.creds['IP']}:{\n",
    "                self.creds['port']}/{database}\"\"\",\n",
    "        )\n",
    "        self.dbmeta = MetaData()\n",
    "        self.dbmeta.reflect(bind=self.dbengine)\n",
    "\n",
    "    def write_to_database(\n",
    "        self, data, table_name, if_exists=\"append\", index=False\n",
    "    ):\n",
    "        \"\"\"\n",
    "        write data to the database\n",
    "\n",
    "        Args:\n",
    "            data: the data to write\n",
    "            table_name: the table name to write to\n",
    "            if_exists: how to handle the write if the table\n",
    "                already exists\n",
    "            index: whether or not to create an index on the table\n",
    "        \"\"\"\n",
    "        if self.dbengine is None:\n",
    "            self.open_connection()\n",
    "        #\n",
    "        if isinstance(data, geopandas.GeoDataFrame):\n",
    "            data = geopandas.GeoDataFrame.to_wkt(data)\n",
    "        #\n",
    "        data.to_sql(\n",
    "            name=table_name,\n",
    "            con=self.dbengine,\n",
    "            if_exists=if_exists,\n",
    "            index=index,\n",
    "            dtype = sqlalchemy.NVARCHAR(),\n",
    "        )\n",
    "\n",
    "def get_sql_connection(\n",
    "        username = '',\n",
    "        password = '',\n",
    "        ip = '',\n",
    "        port = '',\n",
    "    ):\n",
    "    \"\"\"\n",
    "    get a database connection. \n",
    "    # sql to check ip and port\n",
    "    # select distinct local_net_address, local_tcp_port \n",
    "    # from sys.dm_exec_connections where local_net_address is not null\n",
    "\n",
    "    Args:\n",
    "        username: username for database access\n",
    "        password: password for database access\n",
    "        ip: ip address for database\n",
    "        port: port for database\n",
    "    \"\"\"\n",
    "    db = DBUtils()\n",
    "    db.creds['IP'] = ip\n",
    "    db.creds['port'] = port   \n",
    "    db.creds['username'] = username\n",
    "    db.creds['password'] = password\n",
    "    db.open_connection()\n",
    "    \n",
    "    return db\n",
    "\n",
    "def write_redcap_table_to_db(data, table_name, db = None, if_exists = 'replace'):\n",
    "    \"\"\"\n",
    "    write table from redcap into the database, always append 'redcap_' to table name\n",
    "    set to always replace the data in the table\n",
    "\n",
    "    Args:\n",
    "        data: the data to write into the table\n",
    "        table_name: the name of the table to write \n",
    "            (note that 'redcap_' always appended to name)\n",
    "        db: a DBUtils() object where [obj].open_connection() \n",
    "            has been run to init the connection\n",
    "        if_exists: pandas.to_sql() if_exists behavior\n",
    "    \"\"\"\n",
    "    if db is None:\n",
    "        db = get_sql_connection()\n",
    "    db.write_to_database(data, f\"redcap_{table_name}\", if_exists=if_exists)\n",
    "\n",
    "def get_tier_records(\n",
    "        tier, \n",
    "        metadata_data, \n",
    "        record_data, \n",
    "        key_1 = 'patient_tier',\n",
    "        pt_id = 'astropt'\n",
    "    ):\n",
    "    \"\"\"\n",
    "    get the records for a specified tier, always append\n",
    "    ``pt_id`` and drop the descrptive\n",
    "    keys from the table to simplfy. Note that the\n",
    "    ``key_1`` is NULL in the records table so the\n",
    "    filter is a little different.\n",
    "\n",
    "    Args:\n",
    "        tier: the tier to get the records for\n",
    "        metadata_data: the metadata redcap export\n",
    "        record_data: the record redcap export\n",
    "        key_1: the first key in the records table \n",
    "            ('patient_tier' default)\n",
    "        pt_id: The patient identifier ('astropt' default)\n",
    "    \"\"\"\n",
    "    columns = metadata_data.loc[\n",
    "        (metadata_data['form_name'] == tier) & \n",
    "        (metadata_data['field_type'] != 'checkbox') & \n",
    "        (metadata_data['field_type'] != 'descriptive'),\n",
    "        'field_name']\n",
    "    #\n",
    "    # handle checkboxes and ensure the column ordering is correct\n",
    "    #\n",
    "    columns_chckbox = metadata_data.loc[\n",
    "        (metadata_data['form_name'] == tier) & \n",
    "        (metadata_data['field_type'] == 'checkbox'),\n",
    "        'field_name']\n",
    "    columns_chckbox += '___'\n",
    "    columns_chckbox = [col for col in record_data if col.startswith(tuple(columns_chckbox))]\n",
    "    columns_chckbox = pandas.Series(columns_chckbox)\n",
    "    columns = pandas.concat([columns, columns_chckbox])\n",
    "    #\n",
    "    # add 'redcap_repeat_instance', 'redcap_repeat_instrument', and ``pt_id``\n",
    "    # if they are not present\n",
    "    #\n",
    "    if pt_id not in columns.tolist():\n",
    "        columns = pandas.Series(numpy.concatenate(([pt_id], columns.values)))\n",
    "    #\n",
    "    if 'redcap_repeat_instrument' not in columns.tolist():\n",
    "        columns = pandas.Series(numpy.concatenate((['redcap_repeat_instrument'], columns.values)))\n",
    "    #\n",
    "    if 'redcap_repeat_instance' not in columns.tolist():\n",
    "        columns = pandas.Series(numpy.concatenate((['redcap_repeat_instance'], columns.values)))\n",
    "    #\n",
    "    # add the '{tier}_complete' column\n",
    "    #\n",
    "    columns = pandas.Series(numpy.concatenate(([f\"{tier}_complete\"], columns.values)))\n",
    "    #\n",
    "    # The patient tier is not a repeat instrument and the column will be NULL, but\n",
    "    # we want the tables to be consistent so we fill it in.\n",
    "    #\n",
    "    if tier == key_1:\n",
    "        return record_data.loc[record_data['redcap_repeat_instrument'].isna(), record_data.columns.isin(columns)]\n",
    "    #\n",
    "    return record_data.loc[record_data['redcap_repeat_instrument'] == tier, record_data.columns.isin(columns)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, run the last cell. This will read the REDCap data from the 'instrument', 'metadata', 'record', and 'log' tables using the input ``token``. Next, it will build a database connection with the inputs provided above for ``username``, ``password``, ``ip``, and ``port``. Then it will write the 4 tables above into the SQL database in a context named `AstroPathXfer` prepending 'redcap_' to the names. Last, the code will filter the 'metadata' into separate tiers based on the REDCap 'instrument' (or AstroID tiers). The following edits are made to the tables before loading:\n",
    "- Checkboxes are collapsed into a single field\n",
    "- The 'desciptive' fields are filtered out\n",
    "- The 'redcap_repeat_instance', 'redcap_repeat_instrument', and ``pt_id`` ('atroid') columns are prepended if they do not exist\n",
    "- The patient tier (or ``key_1``) is not a repeat instrument and the column will be NULL, but we want the tables to be consistent in the database so we fill it in.\n",
    "\n",
    "Once filtered, we load the tables in the SQL database naming them as 'redcap_``tier_name``'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient_tier\n",
      "diagnosis_tier\n",
      "clinical_tier\n",
      "specimen_tier\n",
      "block_tier\n",
      "slide_tier\n"
     ]
    }
   ],
   "source": [
    "# get redcap tables\n",
    "instrument_data = get_redcap_df(token, 'instrument')\n",
    "metadata_data = get_redcap_df(token, 'metadata')\n",
    "record_data = get_redcap_df(token, 'record')\n",
    "log_data = get_redcap_df(token, 'log')\n",
    "# build database connection to database\n",
    "db = get_sql_connection(username, password, ip, port)\n",
    "# write basic tables\n",
    "write_redcap_table_to_db(instrument_data, 'instrument', db = db)\n",
    "write_redcap_table_to_db(metadata_data, 'metadata', db = db)\n",
    "write_redcap_table_to_db(record_data, 'record', db = db)\n",
    "write_redcap_table_to_db(log_data, 'log', db = db)\n",
    "# filter records and write tables\n",
    "for tier in instrument_data['instrument_name']:\n",
    "    print(tier)\n",
    "    data = get_tier_records(tier, metadata_data, record_data, key_1, pt_id)\n",
    "    write_redcap_table_to_db(data, tier, db = db)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
